{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melting Point Prediction - Enhanced Features\n",
    "\n",
    "## 목표\n",
    "- train_fully.csv (20,182개)로 학습\n",
    "- train.csv (2,662개)로 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n",
      "Seed: 42\n",
      "N_JOBS - Feature: 40, Model: 20\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# RDKit\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem, Fragments, Crippen, Lipinski\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect, ComputeGasteigerCharges\n",
    "from rdkit.Chem.MACCSkeys import GenMACCSKeys\n",
    "from rdkit.Chem.EState import EState_VSA, AtomTypes as EAtomTypes\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "\n",
    "# ML Models\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Optimization\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "SEED = 42\n",
    "N_JOBS_FEATURE = 40\n",
    "N_JOBS_MODEL = 20\n",
    "DATA_PATH = Path('/home/yoo122333/project/saja/data')\n",
    "FEATURE_PATH = Path('/home/yoo122333/project/saja/features')\n",
    "FEATURE_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "print(f\"Setup complete!\")\n",
    "print(f\"Seed: {SEED}\")\n",
    "print(f\"N_JOBS - Feature: {N_JOBS_FEATURE}, Model: {N_JOBS_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20182 samples\n",
      "Val:   2662 samples\n",
      "Test:  666 samples\n"
     ]
    }
   ],
   "source": [
    "# Train: train_fully.csv\n",
    "df_train = pd.read_csv(DATA_PATH / 'train_fully.csv')\n",
    "df_train = df_train[['SMILES', 'Tm']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Val: train.csv\n",
    "df_val = pd.read_csv(DATA_PATH / 'train.csv')\n",
    "df_val = df_val[['id', 'SMILES', 'Tm']].dropna().reset_index(drop=True)\n",
    "\n",
    "# Test: test.csv + submission_v6.csv\n",
    "df_test = pd.read_csv(DATA_PATH / 'test.csv')\n",
    "df_submission = pd.read_csv(DATA_PATH / 'submission_v6.csv')\n",
    "df_test = df_test[['id', 'SMILES']].merge(df_submission, on='id', how='left')\n",
    "\n",
    "print(f\"Train: {len(df_train)} samples\")\n",
    "print(f\"Val:   {len(df_val)} samples\")\n",
    "print(f\"Test:  {len(df_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# Helper functions\n",
    "def _safe(f, default=None):\n",
    "    def wrap(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except Exception:\n",
    "            return default\n",
    "    return wrap\n",
    "\n",
    "def drop_constant_and_duplicate_columns(df):\n",
    "    nunique = df.nunique(dropna=False)\n",
    "    constant_cols = nunique[nunique <= 1].index.tolist()\n",
    "    df = df.drop(columns=constant_cols)\n",
    "    df = df.loc[:, ~df.T.duplicated(keep='first')]\n",
    "    return df\n",
    "\n",
    "def gasteiger_stats(m):\n",
    "    m = Chem.AddHs(m)\n",
    "    ComputeGasteigerCharges(m)\n",
    "    vals = []\n",
    "    for a in m.GetAtoms():\n",
    "        v = a.GetDoubleProp('_GasteigerCharge') if a.HasProp('_GasteigerCharge') else 0.0\n",
    "        if pd.isna(v) or v == float('inf') or v == float('-inf'):\n",
    "            v = 0.0\n",
    "        vals.append(v)\n",
    "    arr = np.array(vals, dtype=float)\n",
    "    return {\n",
    "        \"Gasteiger_q_sum\": float(arr.sum()),\n",
    "        \"Gasteiger_q_abs_sum\": float(np.abs(arr).sum()),\n",
    "        \"Gasteiger_q_min\": float(arr.min(initial=0.0)),\n",
    "        \"Gasteiger_q_max\": float(arr.max(initial=0.0)),\n",
    "        \"Gasteiger_q_std\": float(arr.std(ddof=0)),\n",
    "    }\n",
    "\n",
    "def _bond_order(b):\n",
    "    if b.GetIsAromatic():\n",
    "        return 1.5\n",
    "    t = b.GetBondType()\n",
    "    if t == Chem.BondType.SINGLE: return 1\n",
    "    if t == Chem.BondType.DOUBLE: return 2\n",
    "    if t == Chem.BondType.TRIPLE: return 3\n",
    "    return 0\n",
    "\n",
    "def _ring_size_hist(m):\n",
    "    ri = m.GetRingInfo()\n",
    "    sizes = [len(r) for r in ri.AtomRings()]\n",
    "    out = {5:0, 6:0, 7:0, 8:0}\n",
    "    for s in sizes:\n",
    "        if s in out: out[s] += 1\n",
    "    return out, len(sizes)\n",
    "\n",
    "def _ring_systems_count(m):\n",
    "    ri = m.GetRingInfo()\n",
    "    rings = [set(r) for r in ri.AtomRings()]\n",
    "    if not rings: return 0\n",
    "    seen = set()\n",
    "    sys = 0\n",
    "    for i in range(len(rings)):\n",
    "        if i in seen: continue\n",
    "        sys += 1\n",
    "        stack = [i]\n",
    "        seen.add(i)\n",
    "        while stack:\n",
    "            j = stack.pop()\n",
    "            for k in range(len(rings)):\n",
    "                if k in seen: continue\n",
    "                if rings[j] & rings[k]:\n",
    "                    seen.add(k); stack.append(k)\n",
    "    return sys\n",
    "\n",
    "def _murcko_stats(m):\n",
    "    try:\n",
    "        scaf = MurckoScaffold.GetScaffoldForMol(m)\n",
    "        if scaf is None or scaf.GetNumAtoms() == 0:\n",
    "            return {\"MurckoAtoms\":0, \"MurckoRings\":0, \"MurckoRingSystems\":0, \"SideChainAtoms\":m.GetNumAtoms()}\n",
    "        msys = _ring_systems_count(scaf)\n",
    "        return {\n",
    "            \"MurckoAtoms\": scaf.GetNumAtoms(),\n",
    "            \"MurckoRings\": rdMolDescriptors.CalcNumRings(scaf),\n",
    "            \"MurckoRingSystems\": msys,\n",
    "            \"SideChainAtoms\": m.GetNumAtoms() - scaf.GetNumAtoms(),\n",
    "        }\n",
    "    except:\n",
    "        return {\"MurckoAtoms\":0, \"MurckoRings\":0, \"MurckoRingSystems\":0, \"SideChainAtoms\":m.GetNumAtoms()}\n",
    "\n",
    "def _estate_stats(m):\n",
    "    try:\n",
    "        vals = EAtomTypes.EStateIndices(m)\n",
    "        if not vals: return {\"EState_sum\":0.0,\"EState_mean\":0.0,\"EState_max\":0.0,\"EState_min\":0.0,\"EState_std\":0.0}\n",
    "        arr = np.asarray(vals, dtype=float)\n",
    "        return {\n",
    "            \"EState_sum\": float(arr.sum()),\n",
    "            \"EState_mean\": float(arr.mean()),\n",
    "            \"EState_max\": float(arr.max()),\n",
    "            \"EState_min\": float(arr.min()),\n",
    "            \"EState_std\": float(arr.std(ddof=0)),\n",
    "        }\n",
    "    except:\n",
    "        return {\"EState_sum\":0.0,\"EState_mean\":0.0,\"EState_max\":0.0,\"EState_min\":0.0,\"EState_std\":0.0}\n",
    "\n",
    "def _smiles_morphology(smi: str):\n",
    "    if not smi: \n",
    "        return {\"SMI_len\":0,\"SMI_branches\":0,\"SMI_ringDigits\":0,\"SMI_stereoAt\":0,\"SMI_ezSlashes\":0}\n",
    "    return {\n",
    "        \"SMI_len\": len(smi),\n",
    "        \"SMI_branches\": smi.count(\"(\"),\n",
    "        \"SMI_ringDigits\": sum(ch.isdigit() for ch in smi),\n",
    "        \"SMI_stereoAt\": smi.count(\"@\"),\n",
    "        \"SMI_ezSlashes\": smi.count(\"/\") + smi.count(\"\\\\\"),\n",
    "    }\n",
    "\n",
    "def augment_extra_cheaps(m, row):\n",
    "    bonds = m.GetBonds()\n",
    "    if bonds:\n",
    "        single = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.SINGLE)\n",
    "        double = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.DOUBLE)\n",
    "        triple = sum(1 for b in bonds if b.GetBondType() == Chem.BondType.TRIPLE)\n",
    "        arom = sum(1 for b in bonds if b.GetIsAromatic())\n",
    "        nb = len(bonds)\n",
    "        row[\"FracSingle\"] = single / nb if nb else 0.0\n",
    "        row[\"FracDouble\"] = double / nb if nb else 0.0\n",
    "        row[\"FracAromatic\"] = arom / nb if nb else 0.0\n",
    "        orders = [_bond_order(b) for b in bonds]\n",
    "        row[\"MeanBondOrder\"] = np.mean(orders) if orders else 0.0\n",
    "    else:\n",
    "        row[\"FracSingle\"] = row[\"FracDouble\"] = row[\"FracAromatic\"] = row[\"MeanBondOrder\"] = 0.0\n",
    "    \n",
    "    hist, total_rings = _ring_size_hist(m)\n",
    "    row[\"Ring5\"] = hist[5]\n",
    "    row[\"Ring6\"] = hist[6]\n",
    "    row[\"Ring7\"] = hist[7]\n",
    "    row[\"Ring8\"] = hist[8]\n",
    "    row[\"TotalRings\"] = total_rings\n",
    "    row[\"RingSystems\"] = _ring_systems_count(m)\n",
    "    \n",
    "    murcko = _murcko_stats(m)\n",
    "    row.update(murcko)\n",
    "    \n",
    "    gast = gasteiger_stats(m)\n",
    "    row.update(gast)\n",
    "    \n",
    "    return row\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D shape functions defined\n"
     ]
    }
   ],
   "source": [
    "# 3D Shape features\n",
    "def _shape3d_worker(cansmi: str, maxIters: int = 0):\n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(cansmi)\n",
    "        if m is None:\n",
    "            return cansmi, {}\n",
    "\n",
    "        mH = Chem.AddHs(m)\n",
    "        params = AllChem.ETKDGv3()\n",
    "        params.randomSeed = 123\n",
    "        params.useRandomCoords = True\n",
    "\n",
    "        with Chem.WrapLogs():\n",
    "            cid = AllChem.EmbedMolecule(mH, params)\n",
    "        if cid < 0:\n",
    "            with Chem.WrapLogs():\n",
    "                cid = AllChem.EmbedMolecule(mH, randomSeed=123)\n",
    "            if cid < 0:\n",
    "                return cansmi, {}\n",
    "\n",
    "        if maxIters and maxIters > 0:\n",
    "            try:\n",
    "                with Chem.WrapLogs():\n",
    "                    AllChem.UFFOptimizeMolecule(mH, confId=cid, maxIters=int(maxIters))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        m_noH = Chem.RemoveHs(mH)\n",
    "        confId = 0\n",
    "\n",
    "        out = {}\n",
    "        for nm, fn in [\n",
    "            (\"RadiusOfGyration\", rdMolDescriptors.CalcRadiusOfGyration),\n",
    "            (\"InertialShapeFactor\", rdMolDescriptors.CalcInertialShapeFactor),\n",
    "            (\"PMI1\", rdMolDescriptors.CalcPMI1),\n",
    "            (\"PMI2\", rdMolDescriptors.CalcPMI2),\n",
    "            (\"PMI3\", rdMolDescriptors.CalcPMI3),\n",
    "            (\"NPR1\", rdMolDescriptors.CalcNPR1),\n",
    "            (\"NPR2\", rdMolDescriptors.CalcNPR2),\n",
    "        ]:\n",
    "            try:\n",
    "                with Chem.WrapLogs():\n",
    "                    out[nm] = float(fn(m_noH, confId=confId))\n",
    "            except:\n",
    "                out[nm] = 0.0\n",
    "\n",
    "        pmi1 = out.get(\"PMI1\", 0.0) or 0.0\n",
    "        pmi2 = out.get(\"PMI2\", 0.0) or 0.0\n",
    "        pmi3 = out.get(\"PMI3\", 0.0) or 0.0\n",
    "        out[\"PMI2_over_PMI1\"] = (pmi2 / pmi1) if pmi1 else 0.0\n",
    "        out[\"PMI3_over_PMI1\"] = (pmi3 / pmi1) if pmi1 else 0.0\n",
    "\n",
    "        return cansmi, out\n",
    "    except:\n",
    "        return cansmi, {}\n",
    "\n",
    "def precompute_shape3d_cache(smiles_series, n_jobs=40, maxIters=0):\n",
    "    print(f\"Precomputing 3D shape cache with {n_jobs} cores...\")\n",
    "    \n",
    "    can = smiles_series.astype(str).apply(lambda s: Chem.MolToSmiles(Chem.MolFromSmiles(s), canonical=True)\n",
    "                                          if pd.notna(s) and Chem.MolFromSmiles(s) is not None else None)\n",
    "    uniq = sorted(x for x in set(can.tolist()) if x is not None)\n",
    "\n",
    "    if not uniq:\n",
    "        return {}\n",
    "\n",
    "    print(f\"Computing 3D features for {len(uniq)} unique molecules...\")\n",
    "    results = Parallel(n_jobs=n_jobs, backend=\"loky\", batch_size=64, verbose=10)(\n",
    "        delayed(_shape3d_worker)(s, maxIters) for s in uniq\n",
    "    )\n",
    "    \n",
    "    cache = {k: v for k, v in results if k is not None}\n",
    "    print(f\"3D cache complete: {len(cache)} molecules\")\n",
    "    return cache\n",
    "\n",
    "print(\"3D shape functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdkit_feature_row() defined - ~7000+ features\n"
     ]
    }
   ],
   "source": [
    "# Main feature extraction function\n",
    "def rdkit_feature_row(smiles_str, shape3d_cache=None):\n",
    "    \"\"\"\n",
    "    Extract ~7000+ features:\n",
    "    - RDKit 2D descriptors (~210)\n",
    "    - Morgan FP radius 1,2,3 (3072 bits)\n",
    "    - MACCS Keys (167 bits)\n",
    "    - Atom Pair FP (1024 bits)\n",
    "    - Topological Torsion (1024 bits)\n",
    "    - RDKit FP (2048 bits)\n",
    "    - Avalon FP (1024 bits)\n",
    "    - Element counts, fragments, VSA, EState\n",
    "    - Melting point specific features\n",
    "    - 3D geometry\n",
    "    \"\"\"\n",
    "    row = {}\n",
    "    \n",
    "    try:\n",
    "        m = Chem.MolFromSmiles(smiles_str)\n",
    "        if m is None:\n",
    "            return None\n",
    "        \n",
    "        cansmi = Chem.MolToSmiles(m, canonical=True)\n",
    "        \n",
    "        # 1. RDKit 2D Descriptors\n",
    "        for name, func in Descriptors._descList:\n",
    "            row[name] = _safe(func, 0.0)(m)\n",
    "        \n",
    "        # 2. Basic descriptors\n",
    "        row['MolLogP'] = Crippen.MolLogP(m)\n",
    "        row['TPSA'] = rdMolDescriptors.CalcTPSA(m)\n",
    "        row['NumHDonors'] = Lipinski.NumHDonors(m)\n",
    "        row['NumHAcceptors'] = Lipinski.NumHAcceptors(m)\n",
    "        row['NumRings'] = rdMolDescriptors.CalcNumRings(m)\n",
    "        row['NumAromaticRings'] = rdMolDescriptors.CalcNumAromaticRings(m)\n",
    "        row['NumSaturatedRings'] = rdMolDescriptors.CalcNumSaturatedRings(m)\n",
    "        row['NumAliphaticRings'] = rdMolDescriptors.CalcNumAliphaticRings(m)\n",
    "        row['NumHeteroatoms'] = rdMolDescriptors.CalcNumHeteroatoms(m)\n",
    "        row['NumRotatableBonds'] = rdMolDescriptors.CalcNumRotatableBonds(m)\n",
    "        \n",
    "        # 3. Element counts\n",
    "        for el in ['C', 'H', 'N', 'O', 'S', 'F', 'Cl', 'Br', 'I', 'P']:\n",
    "            row[f'Count_{el}'] = sum(1 for a in m.GetAtoms() if a.GetSymbol() == el)\n",
    "        \n",
    "        # 4. Fragment counts\n",
    "        for attr in dir(Fragments):\n",
    "            if attr.startswith('fr_'):\n",
    "                row[attr] = _safe(getattr(Fragments, attr), 0)(m)\n",
    "        \n",
    "        # 5. EXTENDED FINGERPRINTS\n",
    "        # Morgan radius 1, 2, 3\n",
    "        for radius in [1, 2, 3]:\n",
    "            morgan = GetMorganFingerprintAsBitVect(m, radius=radius, nBits=1024)\n",
    "            for i in range(1024):\n",
    "                row[f'Morgan_r{radius}_{i}'] = morgan[i]\n",
    "        \n",
    "        # MACCS Keys\n",
    "        maccs = GenMACCSKeys(m)\n",
    "        for i in range(167):\n",
    "            row[f'MACCS_{i}'] = maccs[i]\n",
    "        \n",
    "        # Atom Pair\n",
    "        try:\n",
    "            ap = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(m, nBits=1024)\n",
    "            for i in range(1024):\n",
    "                row[f'AtomPair_{i}'] = ap[i]\n",
    "        except:\n",
    "            for i in range(1024):\n",
    "                row[f'AtomPair_{i}'] = 0\n",
    "        \n",
    "        # Topological Torsion\n",
    "        try:\n",
    "            tt = rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(m, nBits=1024)\n",
    "            for i in range(1024):\n",
    "                row[f'TopTorsion_{i}'] = tt[i]\n",
    "        except:\n",
    "            for i in range(1024):\n",
    "                row[f'TopTorsion_{i}'] = 0\n",
    "        \n",
    "        # RDKit Fingerprint\n",
    "        try:\n",
    "            rdk = Chem.RDKFingerprint(m, fpSize=2048)\n",
    "            for i in range(2048):\n",
    "                row[f'RDKitFP_{i}'] = rdk[i]\n",
    "        except:\n",
    "            for i in range(2048):\n",
    "                row[f'RDKitFP_{i}'] = 0\n",
    "        \n",
    "        # Avalon Fingerprint\n",
    "        try:\n",
    "            avalon = pyAvalonTools.GetAvalonFP(m, nBits=1024)\n",
    "            for i in range(1024):\n",
    "                row[f'Avalon_{i}'] = avalon[i]\n",
    "        except:\n",
    "            for i in range(1024):\n",
    "                row[f'Avalon_{i}'] = 0\n",
    "        \n",
    "        # 6. VSA binnings\n",
    "        try:\n",
    "            slogp_vsa = rdMolDescriptors.SlogP_VSA_(m)\n",
    "            for i, v in enumerate(slogp_vsa):\n",
    "                row[f'SlogP_VSA{i}'] = v\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            smr_vsa = rdMolDescriptors.SMR_VSA_(m)\n",
    "            for i, v in enumerate(smr_vsa):\n",
    "                row[f'SMR_VSA{i}'] = v\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            peoe_vsa = rdMolDescriptors.PEOE_VSA_(m)\n",
    "            for i, v in enumerate(peoe_vsa):\n",
    "                row[f'PEOE_VSA{i}'] = v\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 7. EState VSA\n",
    "        try:\n",
    "            estate_vsa = EState_VSA.EState_VSA_(m)\n",
    "            for i, v in enumerate(estate_vsa):\n",
    "                row[f'EState_VSA{i}'] = v\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 8. EState statistics\n",
    "        estate = _estate_stats(m)\n",
    "        row.update(estate)\n",
    "        \n",
    "        # 9. Extra features\n",
    "        row = augment_extra_cheaps(m, row)\n",
    "        \n",
    "        # 10. SMILES morphology\n",
    "        smi_morph = _smiles_morphology(smiles_str)\n",
    "        row.update(smi_morph)\n",
    "        \n",
    "        # 11. MELTING POINT SPECIFIC FEATURES\n",
    "        natoms = m.GetNumAtoms()\n",
    "        \n",
    "        # Molecular symmetry\n",
    "        try:\n",
    "            ranks = Chem.CanonicalRankAtoms(m, breakTies=False)\n",
    "            row['NumSymmetryClasses'] = len(set(ranks))\n",
    "            row['SymmetryRatio'] = len(set(ranks)) / natoms if natoms > 0 else 0\n",
    "        except:\n",
    "            row['NumSymmetryClasses'] = natoms\n",
    "            row['SymmetryRatio'] = 1.0\n",
    "        \n",
    "        # Surface area\n",
    "        try:\n",
    "            row['LabuteASA'] = rdMolDescriptors.CalcLabuteASA(m)\n",
    "        except:\n",
    "            row['LabuteASA'] = 0.0\n",
    "        \n",
    "        # Partial charges\n",
    "        try:\n",
    "            row['MaxPartialCharge'] = Descriptors.MaxPartialCharge(m) or 0.0\n",
    "            row['MinPartialCharge'] = Descriptors.MinPartialCharge(m) or 0.0\n",
    "            row['PartialChargeRange'] = row['MaxPartialCharge'] - row['MinPartialCharge']\n",
    "        except:\n",
    "            row['MaxPartialCharge'] = 0.0\n",
    "            row['MinPartialCharge'] = 0.0\n",
    "            row['PartialChargeRange'] = 0.0\n",
    "        \n",
    "        # Aromatic fraction\n",
    "        aromatic_atoms = sum(1 for a in m.GetAtoms() if a.GetIsAromatic())\n",
    "        row['AromaticAtomFrac'] = aromatic_atoms / natoms if natoms > 0 else 0\n",
    "        \n",
    "        # Heteroatom types\n",
    "        hetero_atoms = [a for a in m.GetAtoms() if a.GetSymbol() not in ['C', 'H']]\n",
    "        row['NumHeteroAtomTypes'] = len(set(a.GetSymbol() for a in hetero_atoms))\n",
    "        \n",
    "        # sp3 fraction\n",
    "        try:\n",
    "            row['FractionCSP3'] = rdMolDescriptors.CalcFractionCSP3(m)\n",
    "        except:\n",
    "            row['FractionCSP3'] = 0.0\n",
    "        \n",
    "        # Hall-Kier Alpha\n",
    "        try:\n",
    "            row['HallKierAlpha'] = Descriptors.HallKierAlpha(m)\n",
    "        except:\n",
    "            row['HallKierAlpha'] = 0.0\n",
    "        \n",
    "        # 12. CUSTOM INTERACTION FEATURES\n",
    "        logp = row.get('MolLogP', 0.0)\n",
    "        tpsa = row.get('TPSA', 1.0)\n",
    "        mw = row.get('MolWt', 1.0)\n",
    "        hbd = row.get('NumHDonors', 0.0)\n",
    "        hba = row.get('NumHAcceptors', 0.0)\n",
    "        nrot = row.get('NumRotatableBonds', 0.0)\n",
    "        nring = row.get('NumRings', 0.0)\n",
    "        narom = row.get('NumAromaticRings', 0.0)\n",
    "        hetero = row.get('NumHeteroatoms', 0.0)\n",
    "        \n",
    "        row['HBondCapacity'] = hbd + hba\n",
    "        row['HBondDensity'] = (hbd + hba) / natoms if natoms > 0 else 0.0\n",
    "        row['HBond_Product'] = hbd * hba\n",
    "        row['Rigidity_Score'] = (nring / natoms) if natoms > 0 else 0.0\n",
    "        row['Flexibility_Score'] = (nrot / natoms) if natoms > 0 else 0.0\n",
    "        row['AromRingFrac'] = (narom / nring) if nring > 0 else 0.0\n",
    "        row['LogP_div_TPSA'] = (logp / tpsa) if tpsa > 0 else 0.0\n",
    "        row['Complexity_per_MW'] = (natoms / mw) if mw > 0 else 0.0\n",
    "        row['HeteroAtomFrac'] = (hetero / natoms) if natoms > 0 else 0.0\n",
    "        row['MW_per_Ring'] = mw / nring if nring > 0 else mw\n",
    "        row['MW_per_RotBond'] = mw / (nrot + 1)\n",
    "        row['LogP_times_MW'] = logp * mw\n",
    "        row['TPSA_per_MW'] = tpsa / mw if mw > 0 else 0.0\n",
    "        \n",
    "        # 13. 3D Shape\n",
    "        if shape3d_cache and cansmi in shape3d_cache:\n",
    "            row.update(shape3d_cache[cansmi])\n",
    "        else:\n",
    "            for k in [\"RadiusOfGyration\", \"InertialShapeFactor\", \n",
    "                     \"PMI1\", \"PMI2\", \"PMI3\", \"NPR1\", \"NPR2\",\n",
    "                     \"PMI2_over_PMI1\", \"PMI3_over_PMI1\"]:\n",
    "                row[k] = 0.0\n",
    "        \n",
    "        return row\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "print(\"rdkit_feature_row() defined - ~7000+ features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurize_smiles() defined\n"
     ]
    }
   ],
   "source": [
    "# Featurization wrapper\n",
    "def featurize_smiles(df, smiles_col='SMILES_can', shape3d_cache=None):\n",
    "    print(f\"Extracting features from {len(df)} molecules...\")\n",
    "    \n",
    "    rows = []\n",
    "    for idx, smi in enumerate(tqdm(df[smiles_col], desc=\"Features\")):\n",
    "        if pd.isna(smi):\n",
    "            rows.append(None)\n",
    "            continue\n",
    "        feat = rdkit_feature_row(smi, shape3d_cache=shape3d_cache)\n",
    "        rows.append(feat)\n",
    "    \n",
    "    df_feat = pd.DataFrame(rows)\n",
    "    print(f\"Initial features: {df_feat.shape[1]} columns\")\n",
    "    \n",
    "    df_feat.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_feat.fillna(0, inplace=True)\n",
    "    \n",
    "    print(\"Removing constant and duplicate columns...\")\n",
    "    df_feat = drop_constant_and_duplicate_columns(df_feat)\n",
    "    print(f\"After cleanup: {df_feat.shape[1]} columns\")\n",
    "    \n",
    "    # Reduce memory\n",
    "    for col in df_feat.select_dtypes(include=['float64']).columns:\n",
    "        df_feat[col] = df_feat[col].astype('float32')\n",
    "    \n",
    "    print(f\"Final shape: {df_feat.shape}\")\n",
    "    print(f\"Memory: {df_feat.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    return df_feat\n",
    "\n",
    "print(\"featurize_smiles() defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction & Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 20182, Val: 2662, Test: 666\n"
     ]
    }
   ],
   "source": [
    "# Canonical SMILES\n",
    "def canonicalize(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return Chem.MolToSmiles(mol, canonical=True) if mol else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_train['SMILES_can'] = df_train['SMILES'].apply(canonicalize)\n",
    "df_val['SMILES_can'] = df_val['SMILES'].apply(canonicalize)\n",
    "df_test['SMILES_can'] = df_test['SMILES'].apply(canonicalize)\n",
    "\n",
    "df_train = df_train[df_train['SMILES_can'].notna()].reset_index(drop=True)\n",
    "df_val = df_val[df_val['SMILES_can'].notna()].reset_index(drop=True)\n",
    "df_test = df_test[df_test['SMILES_can'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing 3D shape cache with 40 cores...\n",
      "Computing 3D features for 20282 unique molecules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=40)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=40)]: Done  20 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=40)]: Done  42 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=40)]: Done  64 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=40)]: Done 648 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=40)]: Done 1232 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=40)]: Done 2192 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=40)]: Done 3152 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=40)]: Done 4240 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=40)]: Done 5328 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=40)]: Done 6544 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=40)]: Done 7760 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=40)]: Done 9104 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=40)]: Done 10448 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=40)]: Done 11920 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=40)]: Done 13392 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=40)]: Done 14992 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=40)]: Done 16592 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=40)]: Done 17789 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=40)]: Done 18160 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=40)]: Done 18305 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=40)]: Done 18450 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=40)]: Done 18605 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=40)]: Done 18760 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=40)]: Done 18925 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=40)]: Done 19090 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=40)]: Done 19265 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=40)]: Done 19440 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=40)]: Done 19625 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=40)]: Done 19810 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=40)]: Done 20005 tasks      | elapsed:   10.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D cache complete: 20282 molecules\n",
      "Saved 3D cache: 20282 molecules\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=40)]: Done 20282 out of 20282 | elapsed:   10.8s finished\n"
     ]
    }
   ],
   "source": [
    "# 3D geometry cache\n",
    "shape3d_cache_path = FEATURE_PATH / 'shape3d_cache_enhanced.pkl'\n",
    "\n",
    "if shape3d_cache_path.exists():\n",
    "    print(\"Loading 3D cache...\")\n",
    "    with open(shape3d_cache_path, 'rb') as f:\n",
    "        shape3d_cache = pickle.load(f)\n",
    "    print(f\"Loaded {len(shape3d_cache)} 3D geometries\")\n",
    "else:\n",
    "    all_smiles = pd.concat([df_train['SMILES_can'], df_val['SMILES_can'], df_test['SMILES_can']]).dropna()\n",
    "    shape3d_cache = precompute_shape3d_cache(all_smiles, n_jobs=N_JOBS_FEATURE, maxIters=0)\n",
    "    \n",
    "    with open(shape3d_cache_path, 'wb') as f:\n",
    "        pickle.dump(shape3d_cache, f)\n",
    "    print(f\"Saved 3D cache: {len(shape3d_cache)} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 20182 molecules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 100%|██████████| 20182/20182 [1:02:35<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features: 8638 columns\n",
      "Removing constant and duplicate columns...\n",
      "After cleanup: 8520 columns\n",
      "Final shape: (20182, 8520)\n",
      "Memory: 1302.02 MB\n",
      "Saved Train features: (20182, 8520)\n"
     ]
    }
   ],
   "source": [
    "# Extract Train features\n",
    "train_feat_path = FEATURE_PATH / 'train_fully_enhanced.pkl'\n",
    "\n",
    "if train_feat_path.exists():\n",
    "    print(\"Loading Train features...\")\n",
    "    df_train_feat = pd.read_pickle(train_feat_path)\n",
    "    print(f\"Loaded: {df_train_feat.shape}\")\n",
    "else:\n",
    "    df_train_feat = featurize_smiles(df_train, smiles_col='SMILES_can', shape3d_cache=shape3d_cache)\n",
    "    df_train_feat.to_pickle(train_feat_path)\n",
    "    print(f\"Saved Train features: {df_train_feat.shape}\")\n",
    "\n",
    "df_train_feat['Tm'] = df_train['Tm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 2662 molecules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 100%|██████████| 2662/2662 [06:46<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features: 8638 columns\n",
      "Removing constant and duplicate columns...\n",
      "After cleanup: 7779 columns\n",
      "Final shape: (2662, 7779)\n",
      "Memory: 156.71 MB\n",
      "Saved Val features: (2662, 7779)\n"
     ]
    }
   ],
   "source": [
    "# Extract Val features\n",
    "val_feat_path = FEATURE_PATH / 'val_enhanced.pkl'\n",
    "\n",
    "if val_feat_path.exists():\n",
    "    print(\"Loading Val features...\")\n",
    "    df_val_feat = pd.read_pickle(val_feat_path)\n",
    "    print(f\"Loaded: {df_val_feat.shape}\")\n",
    "else:\n",
    "    df_val_feat = featurize_smiles(df_val, smiles_col='SMILES_can', shape3d_cache=shape3d_cache)\n",
    "    df_val_feat.to_pickle(val_feat_path)\n",
    "    print(f\"Saved Val features: {df_val_feat.shape}\")\n",
    "\n",
    "df_val_feat['id'] = df_val['id'].values\n",
    "df_val_feat['Tm'] = df_val['Tm'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from 666 molecules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 100%|██████████| 666/666 [01:36<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features: 8638 columns\n",
      "Removing constant and duplicate columns...\n",
      "After cleanup: 6531 columns\n",
      "Final shape: (666, 6531)\n",
      "Memory: 32.87 MB\n",
      "Saved Test features: (666, 6531)\n"
     ]
    }
   ],
   "source": [
    "# Extract Test features\n",
    "test_feat_path = FEATURE_PATH / 'test_enhanced.pkl'\n",
    "\n",
    "if test_feat_path.exists():\n",
    "    print(\"Loading Test features...\")\n",
    "    df_test_feat = pd.read_pickle(test_feat_path)\n",
    "    print(f\"Loaded: {df_test_feat.shape}\")\n",
    "else:\n",
    "    df_test_feat = featurize_smiles(df_test, smiles_col='SMILES_can', shape3d_cache=shape3d_cache)\n",
    "    df_test_feat.to_pickle(test_feat_path)\n",
    "    print(f\"Saved Test features: {df_test_feat.shape}\")\n",
    "\n",
    "df_test_feat['id'] = df_test['id'].values\n",
    "df_test_feat['Tm'] = df_test['Tm'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common features: 6476\n",
      "Train: (20182, 6476)\n",
      "Val:   (2662, 6476)\n",
      "Test:  (666, 6476)\n"
     ]
    }
   ],
   "source": [
    "# Find common features\n",
    "feature_cols = [c for c in df_train_feat.columns if c not in ['Tm', 'id']]\n",
    "val_feature_cols = [c for c in df_val_feat.columns if c not in ['Tm', 'id']]\n",
    "test_feature_cols = [c for c in df_test_feat.columns if c not in ['Tm', 'id']]\n",
    "\n",
    "common_features = sorted(set(feature_cols) & set(val_feature_cols) & set(test_feature_cols))\n",
    "print(f\"Common features: {len(common_features)}\")\n",
    "\n",
    "X_train = df_train_feat[common_features].values\n",
    "y_train = df_train_feat['Tm'].values\n",
    "\n",
    "X_val = df_val_feat[common_features].values\n",
    "y_val = df_val_feat['Tm'].values\n",
    "\n",
    "X_test = df_test_feat[common_features].values\n",
    "y_test = df_test_feat['Tm'].values\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Val:   {X_val.shape}\")\n",
    "print(f\"Test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training ExtraTreesRegressor\n",
      "Train: 20182, Val: 2662\n",
      "============================================================\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved: /home/yoo122333/project/saja/features/extratrees_model.pkl\n",
      "Feature info saved: /home/yoo122333/project/saja/features/feature_info.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Results\n",
      "============================================================\n",
      "Train MAE: 0.0155K\n",
      "Val MAE:   6.7154K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Training ExtraTreesRegressor\")\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train model\n",
    "model = ExtraTreesRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    bootstrap=False,\n",
    "    n_jobs=N_JOBS_MODEL,\n",
    "    random_state=SEED,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "model_path = FEATURE_PATH / 'extratrees_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_info = {\n",
    "    'common_features': common_features,\n",
    "    'n_features': len(common_features)\n",
    "}\n",
    "feature_info_path = FEATURE_PATH / 'feature_info.pkl'\n",
    "with open(feature_info_path, 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(f\"Feature info saved: {feature_info_path}\")\n",
    "\n",
    "# Predictions\n",
    "train_pred = model.predict(X_train)\n",
    "val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "train_mae = mean_absolute_error(y_train, train_pred)\n",
    "val_mae = mean_absolute_error(y_val, val_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Results\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train MAE: {train_mae:.4f}K\")\n",
    "print(f\"Val MAE:   {val_mae:.4f}K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved: /home/yoo122333/project/saja/features/extratrees_model.pkl\n",
      "✓ Feature info saved: /home/yoo122333/project/saja/features/feature_info.pkl\n",
      "\n",
      "Model file size: 271.12 MB\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "model_path = FEATURE_PATH / 'extratrees_model.pkl'\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"✓ Model saved: {model_path}\")\n",
    "\n",
    "# Save feature names\n",
    "feature_info = {\n",
    "    'common_features': common_features,\n",
    "    'n_features': len(common_features)\n",
    "}\n",
    "feature_info_path = FEATURE_PATH / 'feature_info.pkl'\n",
    "with open(feature_info_path, 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "print(f\"✓ Feature info saved: {feature_info_path}\")\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "model_size = os.path.getsize(model_path) / (1024**2)\n",
    "print(f\"\\nModel file size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/yoo122333/project/saja/data/submission_enhanced_features.csv\n",
      "Samples: 666\n",
      "\n",
      "Prediction stats:\n",
      "  Mean: 271.31K\n",
      "  Std:  77.64K\n",
      "  Min:  89.55K\n",
      "  Max:  562.65K\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1022</td>\n",
       "      <td>390.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1146</td>\n",
       "      <td>341.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>185.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2279</td>\n",
       "      <td>206.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1342</td>\n",
       "      <td>231.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2082</td>\n",
       "      <td>337.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>198.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>515</td>\n",
       "      <td>316.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2309</td>\n",
       "      <td>287.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1177</td>\n",
       "      <td>228.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Tm\n",
       "0  1022  390.15\n",
       "1  1146  341.15\n",
       "2    79  185.25\n",
       "3  2279  206.85\n",
       "4  1342  231.45\n",
       "5  2082  337.85\n",
       "6    29  198.15\n",
       "7   515  316.65\n",
       "8  2309  287.65\n",
       "9  1177  228.15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.DataFrame({\n",
    "    'id': df_test['id'].values,\n",
    "    'Tm': test_pred\n",
    "})\n",
    "\n",
    "submit_path = DATA_PATH / 'submission_enhanced_features.csv'\n",
    "df_submit.to_csv(submit_path, index=False)\n",
    "\n",
    "print(f\"Saved: {submit_path}\")\n",
    "print(f\"Samples: {len(df_submit)}\")\n",
    "print(f\"\\nPrediction stats:\")\n",
    "print(f\"  Mean: {df_submit['Tm'].mean():.2f}K\")\n",
    "print(f\"  Std:  {df_submit['Tm'].std():.2f}K\")\n",
    "print(f\"  Min:  {df_submit['Tm'].min():.2f}K\")\n",
    "print(f\"  Max:  {df_submit['Tm'].max():.2f}K\")\n",
    "\n",
    "df_submit.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chemberta_env)",
   "language": "python",
   "name": "chemberta_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
